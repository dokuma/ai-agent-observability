# ===========================================================
# Docker Secrets（オプション）
# secrets/ ディレクトリにファイルを配置すると Docker Secrets 経由で
# 各サービスにシークレットが注入されます。
# 未設定の場合は従来どおり環境変数（.env）が使用されます。
# 詳細: docs/secrets-management.md
# ===========================================================
secrets:
  gf_admin_password:
    file: ./secrets/gf_admin_password
  grafana_service_account_token:
    file: ./secrets/grafana_service_account_token
  postgres_password:
    file: ./secrets/postgres_password
  clickhouse_password:
    file: ./secrets/clickhouse_password
  redis_password:
    file: ./secrets/redis_password
  minio_root_password:
    file: ./secrets/minio_root_password
  langfuse_nextauth_secret:
    file: ./secrets/langfuse_nextauth_secret
  langfuse_salt:
    file: ./secrets/langfuse_salt
  langfuse_encryption_key:
    file: ./secrets/langfuse_encryption_key
  langfuse_init_user_password:
    file: ./secrets/langfuse_init_user_password
  webui_secret_key:
    file: ./secrets/webui_secret_key

services:
  # ===========================================================
  # AI Agent Monitoring アプリケーション
  # ===========================================================
  agent:
    build: .
    ports:
      - "8000:8000"
    env_file:
      - .env
    depends_on:
      ollama:
        condition: service_started
      prometheus-mcp:
        condition: service_started
      loki-mcp:
        condition: service_started
      grafana-mcp:
        condition: service_started
    networks:
      - monitoring

  # ===========================================================
  # LLM — Ollama (qwen2.5:0.5b)
  # ===========================================================
  ollama:
    image: ollama/ollama:latest
    # build:
    #   context: ./deploy/ollama
    #   dockerfile: Dockerfile
    ports:
      - "11434:11434"
    volumes:
      - ./data/ollama:/root/.ollama
    healthcheck:
      test: ["CMD-SHELL", "cat /proc/1/status || exit 0"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - monitoring

  # 起動後にモデルを自動ダウンロード
  ollama-pull:
    image: mirror.gcr.io/curlimages/curl:latest
    depends_on:
      ollama:
        condition: service_started
    entrypoint: >
      sh -c "
        echo 'Pulling qwen2.5:0.5b model...' &&
        curl -sf http://ollama:11434/api/pull -d '{\"name\": \"qwen2.5:0.5b\"}' &&
        echo 'Model pull complete.'
      "
    restart: "no"
    networks:
      - monitoring

  # ===========================================================
  # Monitoring Stack
  # ===========================================================
  prometheus:
    image: mirror.gcr.io/prom/prometheus:v2.53.0
    ports:
      - "9090:9090"
    volumes:
      - ./deploy/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./deploy/prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
      - prometheus_data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.retention.time=7d"
      - "--web.enable-lifecycle"
    networks:
      - monitoring

  loki:
    image: mirror.gcr.io/grafana/loki:3.1.0
    ports:
      - "3100:3100"
    volumes:
      - ./deploy/loki/loki.yml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - monitoring

  promtail:
    image: mirror.gcr.io/grafana/promtail:3.1.0
    volumes:
      - ./deploy/promtail/promtail.yml:/etc/promtail/config.yml:ro
      - /var/log:/var/log:ro
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    networks:
      - monitoring

  grafana:
    image: mirror.gcr.io/grafana/grafana:11.1.0
    ports:
      - "3000:3000"
    volumes:
      - ./deploy/grafana/provisioning:/etc/grafana/provisioning:ro
      - grafana_data:/var/lib/grafana
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: ${GF_ADMIN_PASSWORD:-admin}
      GF_AUTH_ANONYMOUS_ENABLED: "true"
      GF_AUTH_ANONYMOUS_ORG_ROLE: Viewer
      # パネルレンダリング
      GF_RENDERING_SERVER_URL: http://grafana-renderer:8081/render
      GF_RENDERING_CALLBACK_URL: http://grafana:3000/
      GF_LOG_FILTERS: rendering:debug
      # Service Account Token（MCP用）
      GF_SECURITY_SERVICE_ACCOUNT_TOKEN: ${GRAFANA_SERVICE_ACCOUNT_TOKEN:-}
    secrets:
      - gf_admin_password
      - grafana_service_account_token
    depends_on:
      - prometheus
      - loki
    networks:
      - monitoring

  # Grafana 画像レンダラー（パネル PNG 出力に必要）
  grafana-renderer:
    image: grafana/grafana-image-renderer:3.11.1
    # build:
    #   context: ./deploy/grafana-image-renderer
    #   dockerfile: Dockerfile
    ports:
      - "8081:8081"
    environment:
      ENABLE_METRICS: "true"
    networks:
      - monitoring

  # テスト用ダミーアプリ（メトリクス＋ログ生成）
  dummy-app:
    image: mirror.gcr.io/grafana/tns-app:latest
    ports:
      - "8080:80"
    command:
      - -log.level=info
    depends_on:
      - loki
    networks:
      - monitoring

  # ===========================================================
  # MCP Servers
  # ===========================================================
  prometheus-mcp:
    image: prometheus-mcp-server:custom
    # build:
    #   context: ./deploy/prometheus-mcp
    #   dockerfile: Dockerfile
    ports:
      - "9091:8080"
    environment:
      PROMETHEUS_URL: http://prometheus:9090
      PROMETHEUS_MCP_SERVER_TRANSPORT: http
      PROMETHEUS_MCP_BIND_HOST: "0.0.0.0"
      PROMETHEUS_MCP_BIND_PORT: "8080"
    depends_on:
      - prometheus
    networks:
      - monitoring

  loki-mcp:
    build:
      context: ./deploy/loki-mcp
      dockerfile: Dockerfile
    ports:
      - "9092:8080"
    environment:
      LOKI_URL: http://loki:3100
      PORT: "8080"
    depends_on:
      - loki
    networks:
      - monitoring

  grafana-mcp:
    image: grafana/mcp-grafana:latest
    # build:
    #   context: ./deploy/grafana-mcp
    #   dockerfile: Dockerfile
    ports:
      - "9093:8000"
    environment:
      GRAFANA_URL: http://grafana:3000
      GRAFANA_SERVICE_ACCOUNT_TOKEN: ${GRAFANA_SERVICE_ACCOUNT_TOKEN:-glsa_test_token}
    secrets:
      - grafana_service_account_token
    # ログレベルを debug に設定（トラブルシューティング用）
    # 本番環境では --log-level info に戻すこと
    command: ["--transport", "sse", "--address", "0.0.0.0:8000", "--log-level", "debug"]
    depends_on:
      - grafana
    networks:
      - monitoring

  # ===========================================================
  # Langfuse (LLM Observability)
  # ===========================================================
  langfuse-web:
    image: ghcr.io/langfuse/langfuse:latest
    ports:
      - "3001:3000"
    depends_on:
      langfuse-postgres:
        condition: service_healthy
      langfuse-clickhouse:
        condition: service_started
      langfuse-redis:
        condition: service_started
      langfuse-minio:
        condition: service_started
    environment:
      NODE_ENV: production
      DATABASE_URL: postgresql://langfuse:${POSTGRES_PASSWORD:-langfuse}@langfuse-postgres:5432/langfuse
      CLICKHOUSE_MIGRATION_URL: clickhouse://default:${CLICKHOUSE_PASSWORD:-clickhouse}@langfuse-clickhouse:9000
      CLICKHOUSE_URL: http://langfuse-clickhouse:8123
      CLICKHOUSE_USER: default
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-clickhouse}
      CLICKHOUSE_CLUSTER_ENABLED: "false"
      REDIS_HOST: langfuse-redis
      REDIS_PORT: "6379"
      REDIS_AUTH: ${REDIS_PASSWORD:-langfuse-redis-secret}
      LANGFUSE_S3_EVENT_UPLOAD_BUCKET: langfuse
      LANGFUSE_S3_EVENT_UPLOAD_REGION: us-east-1
      LANGFUSE_S3_EVENT_UPLOAD_ENDPOINT: http://langfuse-minio:9000
      LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID: langfuse
      LANGFUSE_S3_EVENT_UPLOAD_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-langfuse-minio-secret}
      LANGFUSE_S3_EVENT_UPLOAD_FORCE_PATH_STYLE: "true"
      LANGFUSE_S3_BATCH_EXPORT_BUCKET: langfuse
      LANGFUSE_S3_BATCH_EXPORT_REGION: us-east-1
      LANGFUSE_S3_BATCH_EXPORT_ENDPOINT: http://langfuse-minio:9000
      LANGFUSE_S3_BATCH_EXPORT_ACCESS_KEY_ID: langfuse
      LANGFUSE_S3_BATCH_EXPORT_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-langfuse-minio-secret}
      LANGFUSE_S3_BATCH_EXPORT_FORCE_PATH_STYLE: "true"
      LANGFUSE_S3_MEDIA_UPLOAD_BUCKET: langfuse
      LANGFUSE_S3_MEDIA_UPLOAD_REGION: us-east-1
      LANGFUSE_S3_MEDIA_UPLOAD_ENDPOINT: http://langfuse-minio:9000
      LANGFUSE_S3_MEDIA_UPLOAD_ACCESS_KEY_ID: langfuse
      LANGFUSE_S3_MEDIA_UPLOAD_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-langfuse-minio-secret}
      LANGFUSE_S3_MEDIA_UPLOAD_FORCE_PATH_STYLE: "true"
      NEXTAUTH_SECRET: ${LANGFUSE_NEXTAUTH_SECRET:-dev-secret-change-in-production}
      SALT: ${LANGFUSE_SALT:-dev-salt-change-in-production}
      ENCRYPTION_KEY: ${LANGFUSE_ENCRYPTION_KEY:-0000000000000000000000000000000000000000000000000000000000000000}
      NEXTAUTH_URL: http://localhost:3001
      LANGFUSE_INIT_ORG_ID: default
      LANGFUSE_INIT_ORG_NAME: "AI Agent Monitoring"
      LANGFUSE_INIT_PROJECT_ID: default
      LANGFUSE_INIT_PROJECT_NAME: "ai-agent-observability"
      LANGFUSE_INIT_PROJECT_PUBLIC_KEY: pk-lf-dev
      LANGFUSE_INIT_PROJECT_SECRET_KEY: sk-lf-dev
      LANGFUSE_INIT_USER_EMAIL: admin@example.com
      LANGFUSE_INIT_USER_NAME: admin
      LANGFUSE_INIT_USER_PASSWORD: ${LANGFUSE_INIT_USER_PASSWORD:-adminadmin}
    secrets:
      - postgres_password
      - clickhouse_password
      - redis_password
      - minio_root_password
      - langfuse_nextauth_secret
      - langfuse_salt
      - langfuse_encryption_key
      - langfuse_init_user_password
    networks:
      - monitoring

  langfuse-worker:
    image: langfuse/langfuse-worker:3
    # build:
    #   context: ./deploy/langfuse-worker
    #   dockerfile: Dockerfile
    depends_on:
      langfuse-postgres:
        condition: service_healthy
      langfuse-clickhouse:
        condition: service_started
      langfuse-redis:
        condition: service_started
    environment:
      NODE_ENV: production
      DATABASE_URL: postgresql://langfuse:${POSTGRES_PASSWORD:-langfuse}@langfuse-postgres:5432/langfuse
      CLICKHOUSE_MIGRATION_URL: clickhouse://default:${CLICKHOUSE_PASSWORD:-clickhouse}@langfuse-clickhouse:9000
      CLICKHOUSE_URL: http://langfuse-clickhouse:8123
      CLICKHOUSE_USER: default
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-clickhouse}
      CLICKHOUSE_CLUSTER_ENABLED: "false"
      REDIS_HOST: langfuse-redis
      REDIS_PORT: "6379"
      REDIS_AUTH: ${REDIS_PASSWORD:-langfuse-redis-secret}
      LANGFUSE_S3_EVENT_UPLOAD_BUCKET: langfuse
      LANGFUSE_S3_EVENT_UPLOAD_REGION: us-east-1
      LANGFUSE_S3_EVENT_UPLOAD_ENDPOINT: http://langfuse-minio:9000
      LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID: langfuse
      LANGFUSE_S3_EVENT_UPLOAD_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-langfuse-minio-secret}
      LANGFUSE_S3_EVENT_UPLOAD_FORCE_PATH_STYLE: "true"
      LANGFUSE_S3_BATCH_EXPORT_BUCKET: langfuse
      LANGFUSE_S3_BATCH_EXPORT_REGION: us-east-1
      LANGFUSE_S3_BATCH_EXPORT_ENDPOINT: http://langfuse-minio:9000
      LANGFUSE_S3_BATCH_EXPORT_ACCESS_KEY_ID: langfuse
      LANGFUSE_S3_BATCH_EXPORT_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-langfuse-minio-secret}
      LANGFUSE_S3_BATCH_EXPORT_FORCE_PATH_STYLE: "true"
      LANGFUSE_S3_MEDIA_UPLOAD_BUCKET: langfuse
      LANGFUSE_S3_MEDIA_UPLOAD_REGION: us-east-1
      LANGFUSE_S3_MEDIA_UPLOAD_ENDPOINT: http://langfuse-minio:9000
      LANGFUSE_S3_MEDIA_UPLOAD_ACCESS_KEY_ID: langfuse
      LANGFUSE_S3_MEDIA_UPLOAD_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-langfuse-minio-secret}
      LANGFUSE_S3_MEDIA_UPLOAD_FORCE_PATH_STYLE: "true"
      ENCRYPTION_KEY: ${LANGFUSE_ENCRYPTION_KEY:-0000000000000000000000000000000000000000000000000000000000000000}
    secrets:
      - postgres_password
      - clickhouse_password
      - redis_password
      - minio_root_password
      - langfuse_encryption_key
    networks:
      - monitoring

  langfuse-postgres:
    image: public.ecr.aws/docker/library/postgres:16-alpine
    environment:
      POSTGRES_USER: langfuse
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-langfuse}
      POSTGRES_DB: langfuse
    secrets:
      - postgres_password
    volumes:
      - langfuse_postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U langfuse"]
      interval: 5s
      timeout: 3s
      retries: 10
    networks:
      - monitoring

  langfuse-clickhouse:
    image: clickhouse/clickhouse-server:24.3
    # build:
    #   context: ./deploy/clickhouse
    #   dockerfile: Dockerfile
    volumes:
      - langfuse_clickhouse_data:/var/lib/clickhouse
      - langfuse_clickhouse_logs:/var/log/clickhouse-server
    environment:
      CLICKHOUSE_DB: default
      CLICKHOUSE_USER: default
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-clickhouse}
    secrets:
      - clickhouse_password
    networks:
      - monitoring

  langfuse-redis:
    image: public.ecr.aws/docker/library/redis:7-alpine
    command: redis-server --requirepass ${REDIS_PASSWORD:-langfuse-redis-secret}
    secrets:
      - redis_password
    volumes:
      - langfuse_redis_data:/data
    networks:
      - monitoring

  langfuse-minio:
    image: mirror.gcr.io/minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: langfuse
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-langfuse-minio-secret}
    secrets:
      - minio_root_password
    volumes:
      - langfuse_minio_data:/data
    networks:
      - monitoring

  # MinIO バケット自動作成
  langfuse-minio-init:
    image: mirror.gcr.io/minio/mc:latest
    depends_on:
      - langfuse-minio
    environment:
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-langfuse-minio-secret}
    secrets:
      - minio_root_password
    entrypoint: >
      sh -c "
        sleep 5 &&
        mc alias set langfuse http://langfuse-minio:9000 langfuse $${MINIO_ROOT_PASSWORD} &&
        mc mb --ignore-existing langfuse/langfuse &&
        echo 'MinIO bucket created.'
      "
    restart: "no"
    networks:
      - monitoring

  # ===========================================================
  # Open WebUI
  # ===========================================================
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "3080:8080"
    environment:
      OLLAMA_BASE_URL: http://ollama:11434
      WEBUI_SECRET_KEY: ${WEBUI_SECRET_KEY:-dev-secret-key}
    secrets:
      - webui_secret_key
    volumes:
      - open_webui_data:/app/backend/data
    depends_on:
      - ollama
    networks:
      - monitoring

volumes:
  open_webui_data:
  prometheus_data:
  loki_data:
  grafana_data:
  langfuse_postgres_data:
  langfuse_clickhouse_data:
  langfuse_clickhouse_logs:
  langfuse_redis_data:
  langfuse_minio_data:

networks:
  monitoring:
    driver: bridge
